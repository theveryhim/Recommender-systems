{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f45a43",
   "metadata": {},
   "source": [
    "# Recommender systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230065b4",
   "metadata": {},
   "source": [
    "## Implementing recommender system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdf70fe",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac11d2c",
   "metadata": {},
   "source": [
    "**item-item collaborative filtering system**\n",
    "\n",
    "- Baseline Estimate Calculation\n",
    "    \n",
    "    Each predicted rating $r_{xi}$ incorporates a baseline estimate $b_{xi}$ , accounting for overall trends:\n",
    "\n",
    "    $$\n",
    "    b_{xi} = \\mu + b_x + b_i\n",
    "    $$\n",
    "\n",
    "    Where:\n",
    "    - $ \\mu $: Overall mean book rating.\n",
    "    - $ b_x = \\bar{r}_x - \\mu $: User $x$'s rating deviation from $\\mu$.\n",
    "    - $ b_i = \\bar{r}_i - \\mu $: Book $i$'s rating deviation from $\\mu$.\n",
    "\n",
    "    > overall_mean = ratings_df.select(F.avg(\"Rating\")).first()[0] <br>\n",
    "    > user_avg = ratings_df.filter(F.col(\"User_Id\") == user_id).select(F.avg(\"Rating\")).first()[0] <br>\n",
    "    > bx = user_avg - overall_mean if user_avg else 0 <br>\n",
    "    > book_avg = ratings_df.filter(F.col(\"Book_Id\") == book_id).select(F.avg(\"Rating\")).first()[0] <br>\n",
    "    > bi = book_avg - overall_mean if book_avg else 0 <br>\n",
    "    > bxi = overall_mean + bx + bi <br>\n",
    "\n",
    "- Similarity Calculation\n",
    "  \n",
    "    The similarity between two books $i$ and $j$, rated by common users, is computed using the **Pearson correlation coefficient**:\n",
    "\n",
    "    $$\n",
    "    s_{ij} = \\frac{\\sum_{u \\in U_{ij}} (r_{ui} - \\bar{r}_i)(r_{uj} - \\bar{r}_j)}{\\sqrt{\\sum_{u \\in U_{ij}} (r_{ui} - \\bar{r}_i)^2} \\sqrt{\\sum_{u \\in U_{ij}} (r_{uj} - \\bar{r}_j)^2}}\n",
    "    $$\n",
    "\n",
    "  - Where:\n",
    "      - $U_{ij}$: Set of users who rated both books $i$ and $j$.\n",
    "      - $ \\bar{r}_i $: Average rating for book $i$.\n",
    "      - $ \\bar{r}_j $: Average rating for book $j$.\n",
    "    \n",
    "    > common_ratings = ratings_i.join(ratings_j, \"User_Id\")<br>\n",
    "    > mean_i = common_ratings.select(F.avg(\"i.Rating\")).first()[0]<br>\n",
    "    > mean_j = common_ratings.select(F.avg(\"j.Rating\")).first()[0]<br>\n",
    "    > numerator = common_ratings.withColumn(\"diff_i\", F.col(\"i.Rating\") - mean_i) \\ <br>\n",
    "    > $\\quad$ .withColumn(\"diff_j\", F.col(\"j.Rating\") - mean_j) \\ <br>\n",
    "    > $\\quad$ .withColumn(\"product\", F.col(\"diff_i\") * F.col(\"diff_j\")) \\ <br>\n",
    "    > $\\quad$ .select(F.sum(\"product\")).first()[0]\n",
    "    \n",
    "\n",
    "- Top- $k$  Nearest Neighbors\n",
    "    - From the set of books rated by the user, the top- $k$ most similar books to the target book $i$ are - selected based on $s_{ij}$.\n",
    "    > similarities = sorted(similarities, key=lambda x: -x[1])[:k]\n",
    "\n",
    "- Rating Prediction\n",
    "  \n",
    "    The predicted rating $r_{xi}$ is calculated as:\n",
    "\n",
    "    $$\n",
    "    r_{xi} = b_{xi} + \\frac{\\sum_{j \\in N(i;x)} s_{ij} \\cdot (r_{xj} - b_{xj})}{\\sum_{j \\in N(i;x)} |s_{ij}|}\n",
    "    $$\n",
    "\n",
    "    Where:\n",
    "    - $ N(i;x) $: Set of top- $k$ similar books to $i$, rated by user $x$.\n",
    "    - $ r_{xj} $: User $x$'s rating for book $j$.\n",
    "    - $ b_{xj} $: Baseline estimate for book $j$.\n",
    "    > numerator = sum(similarity * (rating_j - (overall_mean + bxj)) for _, similarity, rating_j in similarities)<br>\n",
    "    > denominator = sum(abs(similarity) for _, similarity, _ in similarities)<br>\n",
    "    > predicted_rating = bxi + (numerator / denominator if denominator != 0 else 0)<br>\n",
    "\n",
    "- Edge Cases\n",
    "  - **Existing Ratings**: If the user already rated the book, the actual rating is returned.\n",
    "  > if existing_rating:<br>\n",
    "  > $\\quad$ return existing_rating[\"Rating\"]\n",
    "  - **No Neighbors**: If no similar books are found, the baseline estimate \\( b_{xi} \\) is returned.\n",
    "  > if not similarities:<br>\n",
    "  > $\\quad$ return bxi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3220f3",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03e543f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+------+----------+\n",
      "|User_Id       |Book_Id   |Rating|Date      |\n",
      "+--------------+----------+------+----------+\n",
      "|AH2L9G3DQHHAJ |0000000116|4.0   |1019865600|\n",
      "|A2IIIDRK3PRRZY|0000000116|1.0   |1395619200|\n",
      "|A1TADCM7YWPQ8M|0000000868|4.0   |1031702400|\n",
      "|AWGH7V0BDOJKB |0000013714|4.0   |1383177600|\n",
      "|A3UTQPQPM4TQO0|0000013714|5.0   |1374883200|\n",
      "+--------------+----------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"BookRates_DS.csv\", header=False, inferSchema=True)\n",
    "\n",
    "# # Calculate the number of rows\n",
    "n = df.count()\n",
    "\n",
    "# Get the first half of the DataFrame\n",
    "df = df.limit(n//2)\n",
    "\n",
    "# Rename columns\n",
    "df = df.withColumnRenamed(\"_c0\", \"User_Id\") \\\n",
    "       .withColumnRenamed(\"_c1\", \"Book_Id\") \\\n",
    "       .withColumnRenamed(\"_c2\", \"Rating\") \\\n",
    "       .withColumnRenamed(\"_c3\", \"Date\") \\\n",
    "       \n",
    "df.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bf605e",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492a9756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for User AQIY318OX7XYW on Book 0001468685: 1.8137943293929428\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "from math import sqrt\n",
    "\n",
    "def compute_similarity(item_i, item_j, ratings_df):\n",
    "    \"\"\"\n",
    "    Compute the similarity (e.g., Pearson correlation coefficient) between two items.\n",
    "    \"\"\"\n",
    "    # Filter ratings for both items i and j\n",
    "    ratings_i = ratings_df.filter(F.col(\"Book_Id\") == item_i).select(\"User_Id\", \"Rating\").alias(\"i\")\n",
    "    ratings_j = ratings_df.filter(F.col(\"Book_Id\") == item_j).select(\"User_Id\", \"Rating\").alias(\"j\")\n",
    "    \n",
    "    # Join on User_Id\n",
    "    common_ratings = ratings_i.join(ratings_j, \"User_Id\")\n",
    "    \n",
    "    if common_ratings.count() == 0:\n",
    "        return 0  # No common users; similarity is 0\n",
    "    \n",
    "    # Calculate mean ratings for i and j\n",
    "    mean_i = common_ratings.select(F.avg(\"i.Rating\")).first()[0]\n",
    "    mean_j = common_ratings.select(F.avg(\"j.Rating\")).first()[0]\n",
    "    \n",
    "    # Compute numerator and denominator for Pearson correlation\n",
    "    common_ratings = common_ratings.withColumn(\"diff_i\", F.col(\"i.Rating\") - mean_i) \\\n",
    "                                   .withColumn(\"diff_j\", F.col(\"j.Rating\") - mean_j) \\\n",
    "                                   .withColumn(\"product\", F.col(\"diff_i\") * F.col(\"diff_j\"))\n",
    "    \n",
    "    numerator = common_ratings.select(F.sum(\"product\")).first()[0]\n",
    "    denominator = sqrt(common_ratings.select(F.sum(F.col(\"diff_i\") ** 2)).first()[0]) * \\\n",
    "                  sqrt(common_ratings.select(F.sum(F.col(\"diff_j\") ** 2)).first()[0])\n",
    "    \n",
    "    if denominator == 0:\n",
    "        return 0  # Avoid division by zero\n",
    "    \n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "def predict_rating(user_id, book_id, ratings_df, k=5):\n",
    "    \"\"\"\n",
    "    Predict the rating for a given user and book using item-item collaborative filtering.\n",
    "    \"\"\"\n",
    "    # Check if the book is already rated by the user\n",
    "    existing_rating = ratings_df.filter((F.col(\"User_Id\") == user_id) & (F.col(\"Book_Id\") == book_id)).select(\"Rating\").first()\n",
    "    if existing_rating:\n",
    "        return existing_rating[\"Rating\"]  # Return actual rating if already exists\n",
    "    \n",
    "    # Overall mean rating\n",
    "    overall_mean = ratings_df.select(F.avg(\"Rating\")).first()[0]\n",
    "    \n",
    "    # User bias (bx)\n",
    "    user_avg = ratings_df.filter(F.col(\"User_Id\") == user_id).select(F.avg(\"Rating\")).first()[0]\n",
    "    bx = user_avg - overall_mean if user_avg else 0\n",
    "    \n",
    "    # Book bias (bi)\n",
    "    book_avg = ratings_df.filter(F.col(\"Book_Id\") == book_id).select(F.avg(\"Rating\")).first()[0]\n",
    "    bi = book_avg - overall_mean if book_avg else 0\n",
    "    \n",
    "    # Baseline estimate\n",
    "    bxi = overall_mean + bx + bi\n",
    "    \n",
    "    # Find other books rated by the user\n",
    "    user_books = ratings_df.filter(F.col(\"User_Id\") == user_id).select(\"Book_Id\", \"Rating\").collect()\n",
    "    \n",
    "    # Compute similarities with the target book\n",
    "    similarities = []\n",
    "    for row in user_books:\n",
    "        book_j = row[\"Book_Id\"]\n",
    "        rating_j = row[\"Rating\"]\n",
    "        similarity = compute_similarity(book_id, book_j, ratings_df)\n",
    "        if similarity > 0:  # Only consider positive similarities\n",
    "            similarities.append((book_j, similarity, rating_j))\n",
    "    \n",
    "    # Select top-k similar books\n",
    "    similarities = sorted(similarities, key=lambda x: -x[1])[:k]\n",
    "    \n",
    "    if not similarities:\n",
    "        return bxi  # Return baseline estimate if no neighbors are found\n",
    "    \n",
    "    # Compute weighted average\n",
    "    numerator = sum(similarity * (rating_j - (overall_mean + (rating_j - overall_mean))) for _, similarity, rating_j in similarities)\n",
    "    denominator = sum(abs(similarity) for _, similarity, _ in similarities)\n",
    "    \n",
    "    return bxi + (numerator / denominator if denominator != 0 else 0)\n",
    "\n",
    "\n",
    "# Find a random user\n",
    "random_user = df.select(\"User_Id\").distinct().orderBy(F.rand()).first()[0]\n",
    "\n",
    "# Find a book that the user has not rated\n",
    "rated_books = df.filter(F.col(\"User_Id\") == random_user).select(\"Book_Id\").distinct()\n",
    "all_books = df.select(\"Book_Id\").distinct()\n",
    "not_rated_books = all_books.subtract(rated_books)\n",
    "\n",
    "if not_rated_books.count() > 0:\n",
    "    random_book = not_rated_books.orderBy(F.rand()).first()[0]\n",
    "    \n",
    "    # Predict the rating for the not-rated book\n",
    "    predicted_rating = predict_rating(random_user, random_book, df)\n",
    "    print(f\"Predicted rating for User {random_user} on Book {random_book}: {predicted_rating}\")\n",
    "else:\n",
    "    print(f\"No books available that User {random_user} has not rated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3650f3d",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d091513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.0301960237651135\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "import random\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "import math\n",
    "\n",
    "# 1. Select 25% of books randomly\n",
    "books = df.select(\"Book_Id\").distinct().collect()\n",
    "sampled_books = random.sample([row[\"Book_Id\"] for row in books], int(0.25 * len(books)))\n",
    "\n",
    "# 2. Mask 25% of ratings for the sampled books\n",
    "masked_df = df.filter(F.col(\"Book_Id\").isin(sampled_books))\n",
    "unmasked_df = df.subtract(masked_df)\n",
    "\n",
    "# Randomly sample 25% of ratings for the selected books\n",
    "mask_window = Window.partitionBy(\"Book_Id\")\n",
    "masked_df = masked_df.withColumn(\"rand\", F.rand()) \\\n",
    "    .withColumn(\"mask_flag\", F.when(F.col(\"rand\") <= 0.25, 1).otherwise(0)) \\\n",
    "    .filter(F.col(\"mask_flag\") == 1) \\\n",
    "    .drop(\"rand\", \"mask_flag\")\n",
    "\n",
    "# Remaining ratings after masking\n",
    "available_df = df.subtract(masked_df)\n",
    "\n",
    "# Ground truth for masked ratings\n",
    "ground_truth_df = masked_df.select(\"User_Id\", \"Book_Id\", \"Rating\")\n",
    "\n",
    "# Collect item-user ratings into a Python dictionary\n",
    "ratings_data = df.groupBy(\"Book_Id\").agg(F.collect_list(F.struct(\"User_Id\", \"Rating\")).alias(\"ratings\")).collect()\n",
    "\n",
    "# Create a dictionary mapping Book_Id to its ratings\n",
    "item_ratings_dict = {row[\"Book_Id\"]: [(x[\"User_Id\"], x[\"Rating\"]) for x in row[\"ratings\"]] for row in ratings_data}\n",
    "\n",
    "# Broadcast the dictionary\n",
    "item_ratings_broadcast = spark.sparkContext.broadcast(item_ratings_dict)\n",
    "\n",
    "def predict_rating_v01(user_id, book_id, item_ratings):\n",
    "    \"\"\"\n",
    "    Predict the rating for a given user and book using broadcasted data.\n",
    "    \"\"\"\n",
    "    # Baseline predictions (mean ratings)\n",
    "    overall_mean = sum([r for ratings in item_ratings.values() for _, r in ratings]) / sum([len(ratings) for ratings in item_ratings.values()])\n",
    "    user_ratings = [(bid, rating) for bid, ratings in item_ratings.items() for uid, rating in ratings if uid == user_id]\n",
    "\n",
    "    if not user_ratings:\n",
    "        return overall_mean  # Return overall mean if the user has no ratings\n",
    "\n",
    "    # Compute similarity-weighted average\n",
    "    similarities = []\n",
    "    for book_j, rating_j in user_ratings:\n",
    "        ratings_i = item_ratings.get(book_id, [])\n",
    "        ratings_j = item_ratings.get(book_j, [])\n",
    "\n",
    "        # Compute similarity\n",
    "        common_users = set(uid for uid, _ in ratings_i) & set(uid for uid, _ in ratings_j)\n",
    "        if not common_users:\n",
    "            continue\n",
    "\n",
    "        mean_i = sum(r for uid, r in ratings_i if uid in common_users) / len(common_users)\n",
    "        mean_j = sum(r for uid, r in ratings_j if uid in common_users) / len(common_users)\n",
    "\n",
    "        numerator = sum(\n",
    "            (r_i - mean_i) * (r_j - mean_j)\n",
    "            for (uid, r_i) in ratings_i\n",
    "            for (uid_j, r_j) in ratings_j\n",
    "            if uid == uid_j\n",
    "        )\n",
    "        denominator = sqrt(\n",
    "            sum((r_i - mean_i) ** 2 for uid, r_i in ratings_i if uid in common_users) *\n",
    "            sum((r_j - mean_j) ** 2 for uid, r_j in ratings_j if uid in common_users)\n",
    "        )\n",
    "\n",
    "        similarity = numerator / denominator if denominator != 0 else 0\n",
    "        similarities.append((similarity, rating_j))\n",
    "\n",
    "    # Aggregate weighted ratings\n",
    "    numerator = sum(sim * rating for sim, rating in similarities)\n",
    "    denominator = sum(abs(sim) for sim, _ in similarities)\n",
    "\n",
    "    return overall_mean + (numerator / denominator if denominator != 0 else 0)\n",
    "\n",
    "@udf(DoubleType())\n",
    "def predict_rating_udf(user_id, book_id):\n",
    "    return predict_rating_v01(user_id, book_id, item_ratings_broadcast.value)\n",
    "\n",
    "# Generate predictions\n",
    "predictions_df = ground_truth_df.withColumn(\n",
    "    \"Predicted_Rating\",\n",
    "    predict_rating_udf(F.col(\"User_Id\"), F.col(\"Book_Id\"))\n",
    ")\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = predictions_df.withColumn(\n",
    "    \"squared_error\", F.pow(F.col(\"Rating\") - F.col(\"Predicted_Rating\"), 2)\n",
    ").select(F.avg(\"squared_error\").alias(\"mse\")).withColumn(\n",
    "    \"rmse\", F.sqrt(F.col(\"mse\"))\n",
    ").select(\"rmse\").first()[\"rmse\"]\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4491b8",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052622e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# Load the input data\n",
    "df_eval = spark.read.csv(\"Evaluate_P2.csv\", header=False, inferSchema=True)\n",
    "\n",
    "# Rename columns\n",
    "df_eval = df_eval.withColumnRenamed(\"_c0\", \"User_Id\") \\\n",
    "                 .withColumnRenamed(\"_c1\", \"Book_Id\") \\\n",
    "                 .withColumnRenamed(\"_c2\", \"Rating\")\n",
    "\n",
    "# Apply the UDF to estimate ratings for rows with question marks\n",
    "df_with_estimated_ratings = df_eval.withColumn(\n",
    "    \"Rating\",\n",
    "    when(\n",
    "        col(\"Rating\") == \"?\", \n",
    "        predict_rating(col(\"User_Id\"), col(\"Book_Id\"), df)  \n",
    "    ).otherwise(col(\"Rating\"))  \n",
    ")\n",
    "data = df_with_estimated_ratings.select(\"User_Id\", \"Book_Id\", \"Rating\").collect()\n",
    "\n",
    "columns = [\"User_Id\", \"Book_Id\", \"Rating\"]\n",
    "\n",
    "# Create the DataFrame\n",
    "Data_df = pd.DataFrame(data, columns=columns)\n",
    "# Step 4: Save the DataFrame as a CSV file\n",
    "Data_df.to_csv(\"Evaluate_P2.csv\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
